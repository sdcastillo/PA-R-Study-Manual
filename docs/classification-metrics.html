<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 12 Classification metrics | Exam PA Study Guide, Fall 2020</title>
  <meta name="description" content=" 12 Classification metrics | Exam PA Study Guide, Fall 2020" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content=" 12 Classification metrics | Exam PA Study Guide, Fall 2020" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 12 Classification metrics | Exam PA Study Guide, Fall 2020" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/artificial_actuary_logo_favicon.png" type="image/x-icon" />
<link rel="prev" href="glms-for-classification.html"/>
<link rel="next" href="additional-glm-topics.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Exam PA Study Manual</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#faq-frequently-asked-questions"><i class="fa fa-check"></i><b>0.1</b> FAQ: Frequently Asked Questions</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="actuarial-outpost.html"><a href="actuarial-outpost.html"><i class="fa fa-check"></i><b>1</b> Actuarial Outpost</a></li>
<li class="chapter" data-level="2" data-path="the-exam.html"><a href="the-exam.html"><i class="fa fa-check"></i><b>2</b> The exam</a></li>
<li class="chapter" data-level="3" data-path="prometric-demo.html"><a href="prometric-demo.html"><i class="fa fa-check"></i><b>3</b> Prometric Demo</a></li>
<li class="chapter" data-level="4" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>4</b> Introduction</a></li>
<li class="chapter" data-level="5" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>5</b> Getting started</a><ul>
<li class="chapter" data-level="5.1" data-path="getting-started.html"><a href="getting-started.html#download-the-data"><i class="fa fa-check"></i><b>5.1</b> Download the data</a></li>
<li class="chapter" data-level="5.2" data-path="getting-started.html"><a href="getting-started.html#download-islr"><i class="fa fa-check"></i><b>5.2</b> Download ISLR</a></li>
<li class="chapter" data-level="5.3" data-path="getting-started.html"><a href="getting-started.html#new-users"><i class="fa fa-check"></i><b>5.3</b> New users</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="how-much-r-do-i-need-to-know-to-pass.html"><a href="how-much-r-do-i-need-to-know-to-pass.html"><i class="fa fa-check"></i><b>6</b> How much R do I need to know to pass?</a><ul>
<li class="chapter" data-level="6.1" data-path="how-much-r-do-i-need-to-know-to-pass.html"><a href="how-much-r-do-i-need-to-know-to-pass.html#example-soa-pa-61620-task-8"><i class="fa fa-check"></i><b>6.1</b> Example: SOA PA 6/16/20, Task 8</a></li>
<li class="chapter" data-level="6.2" data-path="how-much-r-do-i-need-to-know-to-pass.html"><a href="how-much-r-do-i-need-to-know-to-pass.html#example-2---data-exploration"><i class="fa fa-check"></i><b>6.2</b> Example 2 - Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="r-programming.html"><a href="r-programming.html"><i class="fa fa-check"></i><b>7</b> R programming</a><ul>
<li class="chapter" data-level="7.1" data-path="r-programming.html"><a href="r-programming.html#notebook-chunks"><i class="fa fa-check"></i><b>7.1</b> Notebook chunks</a></li>
<li class="chapter" data-level="7.2" data-path="r-programming.html"><a href="r-programming.html#basic-operations"><i class="fa fa-check"></i><b>7.2</b> Basic operations</a></li>
<li class="chapter" data-level="7.3" data-path="r-programming.html"><a href="r-programming.html#lists"><i class="fa fa-check"></i><b>7.3</b> Lists</a></li>
<li class="chapter" data-level="7.4" data-path="r-programming.html"><a href="r-programming.html#functions"><i class="fa fa-check"></i><b>7.4</b> Functions</a></li>
<li class="chapter" data-level="7.5" data-path="r-programming.html"><a href="r-programming.html#data-frames"><i class="fa fa-check"></i><b>7.5</b> Data frames</a></li>
<li class="chapter" data-level="7.6" data-path="r-programming.html"><a href="r-programming.html#pipes"><i class="fa fa-check"></i><b>7.6</b> Pipes</a></li>
<li class="chapter" data-level="7.7" data-path="r-programming.html"><a href="r-programming.html#the-soas-code-doesnt-use-pipes-or-dplyr-so-can-i-skip-learning-this"><i class="fa fa-check"></i><b>7.7</b> The SOA‚Äôs code doesn‚Äôt use pipes or dplyr, so can I skip learning this?</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-exploration.html"><a href="data-exploration.html"><i class="fa fa-check"></i><b>8</b> Data exploration</a><ul>
<li class="chapter" data-level="8.1" data-path="data-exploration.html"><a href="data-exploration.html#how-to-make-graphs-in-r"><i class="fa fa-check"></i><b>8.1</b> How to make graphs in R</a><ul>
<li class="chapter" data-level="8.1.1" data-path="data-exploration.html"><a href="data-exploration.html#add-a-plot"><i class="fa fa-check"></i><b>8.1.1</b> Add a plot</a></li>
<li class="chapter" data-level="8.1.2" data-path="data-exploration.html"><a href="data-exploration.html#data-manipulation-chaining"><i class="fa fa-check"></i><b>8.1.2</b> Data manipulation chaining</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="data-exploration.html"><a href="data-exploration.html#the-different-graph-types"><i class="fa fa-check"></i><b>8.2</b> The different graph types</a><ul>
<li class="chapter" data-level="8.2.1" data-path="data-exploration.html"><a href="data-exploration.html#histogram"><i class="fa fa-check"></i><b>8.2.1</b> Histogram</a></li>
<li class="chapter" data-level="8.2.2" data-path="data-exploration.html"><a href="data-exploration.html#box-plot"><i class="fa fa-check"></i><b>8.2.2</b> Box plot</a></li>
<li class="chapter" data-level="8.2.3" data-path="data-exploration.html"><a href="data-exploration.html#scatterplot"><i class="fa fa-check"></i><b>8.2.3</b> Scatterplot</a></li>
<li class="chapter" data-level="8.2.4" data-path="data-exploration.html"><a href="data-exploration.html#bar-charts"><i class="fa fa-check"></i><b>8.2.4</b> Bar charts</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data-exploration.html"><a href="data-exploration.html#how-to-save-time-with-dplyr"><i class="fa fa-check"></i><b>8.3</b> How to save time with dplyr</a></li>
<li class="chapter" data-level="8.4" data-path="data-exploration.html"><a href="data-exploration.html#how-to-explore-the-data"><i class="fa fa-check"></i><b>8.4</b> How to explore the data</a></li>
<li class="chapter" data-level="8.5" data-path="data-exploration.html"><a href="data-exploration.html#how-to-transform-the-data"><i class="fa fa-check"></i><b>8.5</b> How to transform the data</a></li>
<li class="chapter" data-level="8.6" data-path="data-exploration.html"><a href="data-exploration.html#example-soa-pa-121219-task-1"><i class="fa fa-check"></i><b>8.6</b> Example: SOA PA 12/12/19, Task 1</a><ul>
<li class="chapter" data-level="8.6.1" data-path="data-exploration.html"><a href="data-exploration.html#garbage-in-garbage-out"><i class="fa fa-check"></i><b>8.6.1</b> Garbage in; garbage out üóë</a></li>
<li class="chapter" data-level="8.6.2" data-path="data-exploration.html"><a href="data-exploration.html#be-a-detective"><i class="fa fa-check"></i><b>8.6.2</b> Be a detective üîç</a></li>
<li class="chapter" data-level="8.6.3" data-path="data-exploration.html"><a href="data-exploration.html#a-picture-is-worth-a-thousand-words"><i class="fa fa-check"></i><b>8.6.3</b> A picture is worth a thousand words üì∑</a></li>
<li class="chapter" data-level="8.6.4" data-path="data-exploration.html"><a href="data-exploration.html#factor-or-numeric"><i class="fa fa-check"></i><b>8.6.4</b> Factor or numeric ‚ùì</a></li>
<li class="chapter" data-level="8.6.5" data-path="data-exploration.html"><a href="data-exploration.html#of-statistics-are-false"><i class="fa fa-check"></i><b>8.6.5</b> 73.6% of statistics are false ü§Ø</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="data-exploration.html"><a href="data-exploration.html#exercises"><i class="fa fa-check"></i><b>8.7</b> Exercises</a></li>
<li class="chapter" data-level="8.8" data-path="data-exploration.html"><a href="data-exploration.html#answers-to-exercises"><i class="fa fa-check"></i><b>8.8</b> Answers to exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html"><i class="fa fa-check"></i><b>9</b> Introduction to modeling</a><ul>
<li class="chapter" data-level="9.1" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#modeling-vocabulary"><i class="fa fa-check"></i><b>9.1</b> Modeling vocabulary</a></li>
<li class="chapter" data-level="9.2" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#modeling-notation"><i class="fa fa-check"></i><b>9.2</b> Modeling notation</a></li>
<li class="chapter" data-level="9.3" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>9.3</b> Ordinary Least Squares (OLS)</a></li>
<li class="chapter" data-level="9.4" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#r2-statistic"><i class="fa fa-check"></i><b>9.4</b> R^2 Statistic</a></li>
<li class="chapter" data-level="9.5" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#correlation"><i class="fa fa-check"></i><b>9.5</b> Correlation</a><ul>
<li class="chapter" data-level="9.5.1" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#pearsons-correlation"><i class="fa fa-check"></i><b>9.5.1</b> Pearson‚Äôs correlation</a></li>
<li class="chapter" data-level="9.5.2" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#spearman-rank-correlation"><i class="fa fa-check"></i><b>9.5.2</b> Spearman (rank) correlation</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#regression-vs.-classification"><i class="fa fa-check"></i><b>9.6</b> Regression vs.¬†classification</a></li>
<li class="chapter" data-level="9.7" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#regression-metrics"><i class="fa fa-check"></i><b>9.7</b> Regression metrics</a><ul>
<li class="chapter" data-level="9.7.1" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#example-soa-pa-61820-task-4"><i class="fa fa-check"></i><b>9.7.1</b> Example: SOA PA 6/18/20, Task 4</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#example-health-costs"><i class="fa fa-check"></i><b>9.8</b> Example: Health Costs</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html"><i class="fa fa-check"></i><b>10</b> Generalized linear Models (GLMs)</a><ul>
<li class="chapter" data-level="10.0.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#assumptions-of-ols"><i class="fa fa-check"></i><b>10.0.1</b> Assumptions of OLS</a></li>
<li class="chapter" data-level="10.0.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#assumptions-of-glms"><i class="fa fa-check"></i><b>10.0.2</b> Assumptions of GLMs</a></li>
<li class="chapter" data-level="10.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>10.1</b> Advantages and disadvantages</a></li>
<li class="chapter" data-level="10.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#glms-for-regression"><i class="fa fa-check"></i><b>10.2</b> GLMs for regression</a></li>
<li class="chapter" data-level="10.3" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>10.3</b> Interpretation of coefficients</a><ul>
<li class="chapter" data-level="10.3.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#identity-link"><i class="fa fa-check"></i><b>10.3.1</b> Identity link</a></li>
<li class="chapter" data-level="10.3.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#log-link"><i class="fa fa-check"></i><b>10.3.2</b> Log link</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#other-links"><i class="fa fa-check"></i><b>10.4</b> Other links</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="glms-for-classification.html"><a href="glms-for-classification.html"><i class="fa fa-check"></i><b>11</b> GLMs for classification</a><ul>
<li class="chapter" data-level="11.1" data-path="glms-for-classification.html"><a href="glms-for-classification.html#binary-target"><i class="fa fa-check"></i><b>11.1</b> Binary target</a></li>
<li class="chapter" data-level="11.2" data-path="glms-for-classification.html"><a href="glms-for-classification.html#count-target"><i class="fa fa-check"></i><b>11.2</b> Count target</a></li>
<li class="chapter" data-level="11.3" data-path="glms-for-classification.html"><a href="glms-for-classification.html#link-functions"><i class="fa fa-check"></i><b>11.3</b> Link functions</a></li>
<li class="chapter" data-level="11.4" data-path="glms-for-classification.html"><a href="glms-for-classification.html#interpretation-of-coefficients-1"><i class="fa fa-check"></i><b>11.4</b> Interpretation of coefficients</a><ul>
<li class="chapter" data-level="11.4.1" data-path="glms-for-classification.html"><a href="glms-for-classification.html#logit"><i class="fa fa-check"></i><b>11.4.1</b> Logit</a></li>
<li class="chapter" data-level="11.4.2" data-path="glms-for-classification.html"><a href="glms-for-classification.html#probit-cauchit-cloglog"><i class="fa fa-check"></i><b>11.4.2</b> Probit, Cauchit, Cloglog</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="glms-for-classification.html"><a href="glms-for-classification.html#demo-the-model-for-interpretation"><i class="fa fa-check"></i><b>11.5</b> Demo the model for interpretation</a></li>
<li class="chapter" data-level="11.6" data-path="glms-for-classification.html"><a href="glms-for-classification.html#example-soa-hr-task-5"><i class="fa fa-check"></i><b>11.6</b> Example: SOA HR, Task 5</a></li>
<li class="chapter" data-level="11.7" data-path="glms-for-classification.html"><a href="glms-for-classification.html#example-soa-pa-121219-task-11"><i class="fa fa-check"></i><b>11.7</b> Example: SOA PA 12/12/19, Task 11</a></li>
<li class="chapter" data-level="11.8" data-path="glms-for-classification.html"><a href="glms-for-classification.html#example---auto-claims"><i class="fa fa-check"></i><b>11.8</b> Example - Auto Claims</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="classification-metrics.html"><a href="classification-metrics.html"><i class="fa fa-check"></i><b>12</b> Classification metrics</a><ul>
<li class="chapter" data-level="12.1" data-path="classification-metrics.html"><a href="classification-metrics.html#area-under-the-roc-curve-auc"><i class="fa fa-check"></i><b>12.1</b> Area Under the ROC Curve (AUC)</a><ul>
<li class="chapter" data-level="12.1.1" data-path="classification-metrics.html"><a href="classification-metrics.html#example---auto-claims-1"><i class="fa fa-check"></i><b>12.1.1</b> Example - Auto Claims</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="classification-metrics.html"><a href="classification-metrics.html#additional-reading"><i class="fa fa-check"></i><b>12.2</b> Additional reading</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html"><i class="fa fa-check"></i><b>13</b> Additional GLM topics</a><ul>
<li class="chapter" data-level="13.1" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#residuals"><i class="fa fa-check"></i><b>13.1</b> Residuals</a><ul>
<li class="chapter" data-level="13.1.1" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#raw-residuals"><i class="fa fa-check"></i><b>13.1.1</b> Raw residuals</a></li>
<li class="chapter" data-level="13.1.2" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#deviance-residuals"><i class="fa fa-check"></i><b>13.1.2</b> Deviance residuals</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#example"><i class="fa fa-check"></i><b>13.2</b> Example</a></li>
<li class="chapter" data-level="13.3" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#log-transforms-of-predictors"><i class="fa fa-check"></i><b>13.3</b> Log transforms of predictors</a></li>
<li class="chapter" data-level="13.4" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#reference-levels"><i class="fa fa-check"></i><b>13.4</b> Reference levels</a></li>
<li class="chapter" data-level="13.5" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#interactions"><i class="fa fa-check"></i><b>13.5</b> Interactions</a></li>
<li class="chapter" data-level="13.6" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#offsets"><i class="fa fa-check"></i><b>13.6</b> Offsets</a></li>
<li class="chapter" data-level="13.7" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#tweedie-regression"><i class="fa fa-check"></i><b>13.7</b> Tweedie regression</a></li>
<li class="chapter" data-level="13.8" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#combinations-of-link-functions-and-target-distributions"><i class="fa fa-check"></i><b>13.8</b> Combinations of Link Functions and Target Distributions</a><ul>
<li class="chapter" data-level="13.8.1" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-log-link"><i class="fa fa-check"></i><b>13.8.1</b> Gaussian Response with Log Link</a></li>
<li class="chapter" data-level="13.8.2" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-inverse-link"><i class="fa fa-check"></i><b>13.8.2</b> Gaussian Response with Inverse Link</a></li>
<li class="chapter" data-level="13.8.3" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-identity-link"><i class="fa fa-check"></i><b>13.8.3</b> Gaussian Response with Identity Link</a></li>
<li class="chapter" data-level="13.8.4" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-log-link-and-negative-values"><i class="fa fa-check"></i><b>13.8.4</b> Gaussian Response with Log Link and Negative Values</a></li>
<li class="chapter" data-level="13.8.5" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gamma-response-with-log-link"><i class="fa fa-check"></i><b>13.8.5</b> Gamma Response with Log Link</a></li>
<li class="chapter" data-level="13.8.6" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gamma-with-inverse-link"><i class="fa fa-check"></i><b>13.8.6</b> Gamma with Inverse Link</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html"><i class="fa fa-check"></i><b>14</b> GLM variable selection</a><ul>
<li class="chapter" data-level="14.1" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#stepwise-subset-selection"><i class="fa fa-check"></i><b>14.1</b> Stepwise subset selection</a></li>
<li class="chapter" data-level="14.2" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#example-soa-pa-61219-task-6"><i class="fa fa-check"></i><b>14.2</b> Example: SOA PA 6/12/19, Task 6</a></li>
<li class="chapter" data-level="14.3" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#penalized-linear-models"><i class="fa fa-check"></i><b>14.3</b> Penalized Linear Models</a></li>
<li class="chapter" data-level="14.4" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#ridge-regression"><i class="fa fa-check"></i><b>14.4</b> Ridge Regression</a></li>
<li class="chapter" data-level="14.5" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#lasso"><i class="fa fa-check"></i><b>14.5</b> Lasso</a></li>
<li class="chapter" data-level="14.6" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#elastic-net"><i class="fa fa-check"></i><b>14.6</b> Elastic Net</a></li>
<li class="chapter" data-level="14.7" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#advantages-and-disadvantages-1"><i class="fa fa-check"></i><b>14.7</b> Advantages and disadvantages</a></li>
<li class="chapter" data-level="14.8" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#example-ridge-regression"><i class="fa fa-check"></i><b>14.8</b> Example: Ridge Regression</a></li>
<li class="chapter" data-level="14.9" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#example-the-lasso"><i class="fa fa-check"></i><b>14.9</b> Example: The Lasso</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html"><i class="fa fa-check"></i><b>15</b> Bias-variance trade-off</a><ul>
<li class="chapter" data-level="15.1" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html#references"><i class="fa fa-check"></i><b>15.1</b> References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>16</b> Tree-based models</a><ul>
<li class="chapter" data-level="16.1" data-path="tree-based-models.html"><a href="tree-based-models.html#decision-trees"><i class="fa fa-check"></i><b>16.1</b> Decision Trees</a><ul>
<li class="chapter" data-level="16.1.1" data-path="tree-based-models.html"><a href="tree-based-models.html#example-soa-pa-6182020-task-6"><i class="fa fa-check"></i><b>16.1.1</b> Example: SOA PA 6/18/2020, Task 6</a></li>
<li class="chapter" data-level="16.1.2" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-2"><i class="fa fa-check"></i><b>16.1.2</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="tree-based-models.html"><a href="tree-based-models.html#ensemble-learning"><i class="fa fa-check"></i><b>16.2</b> Ensemble learning</a><ul>
<li class="chapter" data-level="16.2.1" data-path="tree-based-models.html"><a href="tree-based-models.html#bagging"><i class="fa fa-check"></i><b>16.2.1</b> Bagging</a></li>
<li class="chapter" data-level="16.2.2" data-path="tree-based-models.html"><a href="tree-based-models.html#boosting"><i class="fa fa-check"></i><b>16.2.2</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="tree-based-models.html"><a href="tree-based-models.html#random-forests"><i class="fa fa-check"></i><b>16.3</b> Random Forests</a><ul>
<li class="chapter" data-level="16.3.1" data-path="tree-based-models.html"><a href="tree-based-models.html#example-1"><i class="fa fa-check"></i><b>16.3.1</b> Example</a></li>
<li class="chapter" data-level="16.3.2" data-path="tree-based-models.html"><a href="tree-based-models.html#variable-importance"><i class="fa fa-check"></i><b>16.3.2</b> Variable Importance</a></li>
<li class="chapter" data-level="16.3.3" data-path="tree-based-models.html"><a href="tree-based-models.html#partial-dependence"><i class="fa fa-check"></i><b>16.3.3</b> Partial dependence</a></li>
<li class="chapter" data-level="16.3.4" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-3"><i class="fa fa-check"></i><b>16.3.4</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="tree-based-models.html"><a href="tree-based-models.html#gradient-boosted-trees"><i class="fa fa-check"></i><b>16.4</b> Gradient Boosted Trees</a><ul>
<li class="chapter" data-level="16.4.1" data-path="tree-based-models.html"><a href="tree-based-models.html#gradient-boosting"><i class="fa fa-check"></i><b>16.4.1</b> Gradient Boosting</a></li>
<li class="chapter" data-level="16.4.2" data-path="tree-based-models.html"><a href="tree-based-models.html#notation"><i class="fa fa-check"></i><b>16.4.2</b> Notation</a></li>
<li class="chapter" data-level="16.4.3" data-path="tree-based-models.html"><a href="tree-based-models.html#parameters"><i class="fa fa-check"></i><b>16.4.3</b> Parameters</a></li>
<li class="chapter" data-level="16.4.4" data-path="tree-based-models.html"><a href="tree-based-models.html#example-2"><i class="fa fa-check"></i><b>16.4.4</b> Example</a></li>
<li class="chapter" data-level="16.4.5" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-4"><i class="fa fa-check"></i><b>16.4.5</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="tree-based-models.html"><a href="tree-based-models.html#exercises-1"><i class="fa fa-check"></i><b>16.5</b> Exercises</a><ul>
<li class="chapter" data-level="16.5.1" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-with-randomforest"><i class="fa fa-check"></i><b>16.5.1</b> 1. RF with <code>randomForest</code></a></li>
<li class="chapter" data-level="16.5.2" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-tuning-with-caret"><i class="fa fa-check"></i><b>16.5.2</b> 2. RF tuning with <code>caret</code></a></li>
<li class="chapter" data-level="16.5.3" data-path="tree-based-models.html"><a href="tree-based-models.html#tuning-a-gbm-with-caret"><i class="fa fa-check"></i><b>16.5.3</b> 3. Tuning a GBM with <code>caret</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>17</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="17.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#principal-component-analysis-pca"><i class="fa fa-check"></i><b>17.1</b> Principal Component Analysis (PCA)</a><ul>
<li class="chapter" data-level="17.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#example-pca-on-us-arrests"><i class="fa fa-check"></i><b>17.1.1</b> Example: PCA on US Arrests</a></li>
<li class="chapter" data-level="17.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#example-pca-on-cancel-cells"><i class="fa fa-check"></i><b>17.1.2</b> Example: PCA on Cancel Cells</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering"><i class="fa fa-check"></i><b>17.2</b> Clustering</a><ul>
<li class="chapter" data-level="17.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-clustering"><i class="fa fa-check"></i><b>17.2.1</b> K-Means Clustering</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#hierarchical-clustering"><i class="fa fa-check"></i><b>17.3</b> Hierarchical Clustering</a><ul>
<li class="chapter" data-level="17.3.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#example-clustering-cancel-cells"><i class="fa fa-check"></i><b>17.3.1</b> Example: Clustering Cancel Cells</a></li>
<li class="chapter" data-level="17.3.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#references-1"><i class="fa fa-check"></i><b>17.3.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="references-2.html"><a href="references-2.html"><i class="fa fa-check"></i><b>18</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Exam PA Study Guide, Fall 2020</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification-metrics" class="section level1">
<h1><span class="header-section-number"> 12</span> Classification metrics</h1>
<p>For regression problems, when the output is a whole number, we can use the sum of squares <span class="math inline">\(\text{RSS}\)</span>, the r-squared <span class="math inline">\(R^2\)</span>, the mean absolute error <span class="math inline">\(\text{MAE}\)</span>, and the likelihood. For classification problems we need to a new set of metrics.</p>
<p>A <em>confusion matrix</em> shows is a table that summarizes how the model classifies each group.</p>
<ul>
<li>No claims and predicted to not have claims - <strong>True Negatives (TN) = 1,489</strong></li>
<li>Had claims and predicted to have claims - <strong>True Positives (TP) = 59</strong></li>
<li>No claims but predicted to have claims - <strong>False Positives (FP) = 22</strong></li>
<li>Had claims but predicted not to - <strong>False Negatives (FN) = 489</strong></li>
</ul>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb242-1" title="1"><span class="kw">confusionMatrix</span>(test<span class="op">$</span>pred_zero_one,<span class="kw">factor</span>(test<span class="op">$</span>target))<span class="op">$</span>table</a></code></pre></div>
<pre><code>##           Reference
## Prediction    0    1
##          0 1489  489
##          1   22   59</code></pre>
<p>These definitions allow us to measure performance on the different groups.</p>
<p><em>Precision</em> answers the question ‚Äúout of all of the positive predictions, what percentage were correct?‚Äù</p>
<p><span class="math display">\[\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}\]</span></p>
<p><em>Recall</em> answers the question ‚Äúout of all of positive examples in the data set, what percentage were correct?‚Äù</p>
<p><span class="math display">\[\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\]</span></p>
<p>The choice of using precision vs.¬†recall depends on the relative cost of making a FP or a FN error. If FP errors are expensive, then use precision; if FN errors are expensive, then use recall.</p>
<p><strong>Example A:</strong> the model trying to detect a deadly disease, which only 1 out of every 1,000 patient‚Äôs survive without early detection. Then the goal should be to optimize <em>recall</em>, because we would want every patient that has the disease to get detected.</p>
<p><strong>Example B:</strong> the model is detecting which emails are spam or not. If an important email is flagged as spam incorrectly, the cost is 5 hours of lost productivity. In this case, <em>precision</em> is the main concern.</p>
<p>In some cases we can compare this ‚Äúcost‚Äù in actual values. For example, if a federal court is predicting if a criminal will recommit or not, they can agree that ‚Äú1 out of every 20 guilty individuals going free‚Äù in exchange for ‚Äú90% of those who are guilty being convicted‚Äù. When money is involved, a dollar amount can be used: flagging non-spam as spam may cost $100 whereas missing a spam email may cost $2. Then the cost-weighted accuracy is</p>
<p><span class="math display">\[\text{Cost} = (100)(\text{FN}) + (2)(\text{FP})\]</span></p>
<p>The cutoff value can be tuned in order to find the minimum cost.</p>
<p>Fortunately, all of this is handled in a single function called <code>confusionMatrix</code>.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb244-1" title="1"><span class="kw">confusionMatrix</span>(test<span class="op">$</span>pred_zero_one,<span class="kw">factor</span>(test<span class="op">$</span>target))</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1489  489
##          1   22   59
##                                           
##                Accuracy : 0.7518          
##                  95% CI : (0.7326, 0.7704)
##     No Information Rate : 0.7339          
##     P-Value [Acc &gt; NIR] : 0.03366         
##                                           
##                   Kappa : 0.1278          
##                                           
##  Mcnemar&#39;s Test P-Value : &lt; 2e-16         
##                                           
##             Sensitivity : 0.9854          
##             Specificity : 0.1077          
##          Pos Pred Value : 0.7528          
##          Neg Pred Value : 0.7284          
##              Prevalence : 0.7339          
##          Detection Rate : 0.7232          
##    Detection Prevalence : 0.9607          
##       Balanced Accuracy : 0.5466          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<div id="area-under-the-roc-curve-auc" class="section level2">
<h2><span class="header-section-number">12.1</span> Area Under the ROC Curve (AUC)</h2>
<p>What if we look at both the true-positive rate (TPR) and false positive rate (FPR) simultaneously? That is, for each value of the cutoff, we can calculate the TPR and TNR.</p>
<p>For example, say that we have 10 cutoff values, <span class="math inline">\(\{k_1, k_2, ..., k_{10}\}\)</span>. Then for each value of <span class="math inline">\(k\)</span> we calculate both the true positive rates</p>
<p><span class="math display">\[\text{TPR} = \{\text{TPR}(k_1), \text{TPR}(k_2), .., \text{TPR}(k_{10})\} \]</span></p>
<p>and the true negative rates</p>
<p><span class="math display">\[\{\text{FNR} = \{\text{FNR}(k_1), \text{FNR}(k_2), .., \text{FNR}(k_{10})\}\]</span></p>
<p>Then we set <code>x = TPR</code> and <code>y = FNR</code> and graph x against y. The resulting plot is called the <strong>Receiver Operator Curve (ROC)</strong> and the the Area Under the Curve is called the AUC.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/4jRBRDbJemM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>You can also think of AUC as being a <strong>probability.</strong> Unlike a conventional probability, this ranges between 0.5 and 1 instead of 0 and 1. In the Logit example, we were predicting whether or not an auto policy would file a claim. Then you can interpret the AUC as</p>
<ul>
<li><p>The expected proportion of positives ranked before a uniformly drawn random negative</p></li>
<li><p>The probability that a model prediction for a policy which actually filed a claim is greater than the model prediction for a policy which did not file a claim</p></li>
<li><p>The expected true positive rate if the ranking is split just before a uniformly drawn random negative.</p></li>
<li><p>The expected proportion of negatives ranked after a uniformly drawn random positive.</p></li>
<li><p>The expected false positive rate if the ranking is split just after a uniformly drawn random positive.</p></li>
</ul>
<p>You can save yourself time by memorizing these three scenarios:</p>
<p><span class="math display">\[ \text{AUC} = 1.0 \]</span></p>
<p><img src="images/auc_one.PNG" width="50%" style="display: block; margin: auto;" /></p>
<p>This is a perfect model that predicts the correct class for new data each time. It will have a ROC plot showing the curve approaching the top left corner so that the area of the square is 1.0.</p>
<p><span class="math display">\[ \text{AUC} = 0.5 \]</span>*</p>
<p><img src="images/auc_point_five.png" width="50%" style="display: block; margin: auto;" /></p>
<p>When the ROC curve runs along the diagonal then the area is 0.5. This performance is no better than randomly selecting the class for new data such that the proportions of each class matches that of the data.</p>
<p><span class="math display">\[ \text{AUC} &lt; 0.5 \]</span>
Any model having an AUC less than 0.5 means it is providing predictions that are worse than random selection, with a near 0 AUC indicating that the model makes the wrong classification almost every time. This can occur in two ways</p>
<ol style="list-style-type: decimal">
<li><p>The model is overfitting. For example, the AUC on the train data set may be higher than 0.8 but only 0.2 on the test data set. This indicates that you need to adjust your model‚Äôs parameters. See the chapter on the Bias-Variance Tradeoff.</p></li>
<li><p>There is an error in the AUC calculation or model prediction.</p></li>
</ol>
<div id="example---auto-claims-1" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Example - Auto Claims</h3>
<p>Let‚Äôs create an ROC curve and find the AUC for our logit.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb246-1" title="1"><span class="kw">library</span>(pROC)</a>
<a class="sourceLine" id="cb246-2" title="2"><span class="kw">roc</span>(test<span class="op">$</span>target, preds, <span class="dt">plot =</span> T)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-147"></span>
<img src="Exam-PA-Study-Manual_files/figure-html/unnamed-chunk-147-1.png" alt="AUC for auto_claim" width="576" />
<p class="caption">
Figure 12.1: AUC for auto_claim
</p>
</div>
<pre><code>## 
## Call:
## roc.default(response = test$target, predictor = preds, plot = T)
## 
## Data: preds in 1511 controls (test$target 0) &lt; 548 cases (test$target 1).
## Area under the curve: 0.7558</code></pre>
<p>If we just randomly guess, the AUC would be 0.5, which is represented by the 45-degree line. A perfect model would maximize the curve to the upper-left corner.</p>
<p>The AUC of 0.76 is decent. If we had multiple models we could compare them based on the AUC.</p>
<p>In general, AUC is preferred over Accuracy when there are a lot more ‚Äútrue‚Äù classes than ‚Äúfalse‚Äù classes, which is known as having <em>class imbalance</em>. An example is bank fraud detection: 99.99% of bank transactions are ‚Äúfalse‚Äù or ‚Äú0‚Äù classes, and so optimizing for accuracy alone will result in a low sensitivity for detecting actual fraud.</p>
</div>
</div>
<div id="additional-reading" class="section level2">
<h2><span class="header-section-number">12.2</span> Additional reading</h2>
<table>
<thead>
<tr class="header">
<th>Title</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>An Overview of Classification</td>
<td>ISL 4.1</td>
</tr>
<tr class="even">
<td><a href="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5#:~:targetText=What%20is%20AUC%20%2D%20ROC%20Curve%3F,capable%20of%20distinguishing%20between%20classes.">Understanding AUC - ROC Curv</a></td>
<td>Sarang Narkhede, Towards Data Science</td>
</tr>
<tr class="odd">
<td><a href="https://towardsdatascience.com/precision-vs-recall-386cf9f89488#:~:targetText=Precision%20and%20recall%20are%20two,correctly%20classified%20by%20your%20algorithm.">Precision vs.¬†Recall</a></td>
<td>Shruti Saxena, Towards Data Science</td>
</tr>
</tbody>
</table>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="glms-for-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="additional-glm-topics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sdcastillo/PA-R-Study-Manual/edit/master/04-linear-models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Exam-PA-Study-Manual.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
