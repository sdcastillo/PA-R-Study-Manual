<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 13 GLMs for classification | Predictive Analytics for Actuaries</title>
  <meta name="description" content=" 13 GLMs for classification | Predictive Analytics for Actuaries" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content=" 13 GLMs for classification | Predictive Analytics for Actuaries" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 13 GLMs for classification | Predictive Analytics for Actuaries" />
  
  
  

<meta name="author" content="Sam Castillo" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/artificial_actuary_logo_favicon.png" type="image/x-icon" />
<link rel="prev" href="generalized-linear-models-glms.html"/>
<link rel="next" href="classification-metrics.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Exam PA Study Manual</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="join-the-online-course.html"><a href="join-the-online-course.html"><i class="fa fa-check"></i><b>1</b> Join the online course</a></li>
<li class="chapter" data-level="2" data-path="how-to-use-this-book.html"><a href="how-to-use-this-book.html"><i class="fa fa-check"></i><b>2</b> How to use this book</a></li>
<li class="chapter" data-level="3" data-path="how-to-contribute-to-this-book.html"><a href="how-to-contribute-to-this-book.html"><i class="fa fa-check"></i><b>3</b> How to Contribute to this book</a></li>
<li class="chapter" data-level="4" data-path="the-exam.html"><a href="the-exam.html"><i class="fa fa-check"></i><b>4</b> The exam</a></li>
<li class="chapter" data-level="5" data-path="prometric-demo.html"><a href="prometric-demo.html"><i class="fa fa-check"></i><b>5</b> Prometric Demo</a></li>
<li class="chapter" data-level="6" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>6</b> Introduction</a></li>
<li class="chapter" data-level="7" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>7</b> Getting started</a><ul>
<li class="chapter" data-level="7.1" data-path="getting-started.html"><a href="getting-started.html#download-the-data"><i class="fa fa-check"></i><b>7.1</b> Download the data</a></li>
<li class="chapter" data-level="7.2" data-path="getting-started.html"><a href="getting-started.html#download-islr"><i class="fa fa-check"></i><b>7.2</b> Download ISLR</a></li>
<li class="chapter" data-level="7.3" data-path="getting-started.html"><a href="getting-started.html#new-users"><i class="fa fa-check"></i><b>7.3</b> New users</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="r-programming.html"><a href="r-programming.html"><i class="fa fa-check"></i><b>8</b> R programming</a><ul>
<li class="chapter" data-level="8.1" data-path="r-programming.html"><a href="r-programming.html#notebook-chunks"><i class="fa fa-check"></i><b>8.1</b> Notebook chunks</a></li>
<li class="chapter" data-level="8.2" data-path="r-programming.html"><a href="r-programming.html#basic-operations"><i class="fa fa-check"></i><b>8.2</b> Basic operations</a></li>
<li class="chapter" data-level="8.3" data-path="r-programming.html"><a href="r-programming.html#lists"><i class="fa fa-check"></i><b>8.3</b> Lists</a></li>
<li class="chapter" data-level="8.4" data-path="r-programming.html"><a href="r-programming.html#functions"><i class="fa fa-check"></i><b>8.4</b> Functions</a></li>
<li class="chapter" data-level="8.5" data-path="r-programming.html"><a href="r-programming.html#data-frames"><i class="fa fa-check"></i><b>8.5</b> Data frames</a></li>
<li class="chapter" data-level="8.6" data-path="r-programming.html"><a href="r-programming.html#pipes"><i class="fa fa-check"></i><b>8.6</b> Pipes</a></li>
<li class="chapter" data-level="8.7" data-path="r-programming.html"><a href="r-programming.html#the-soas-code-doesnt-use-pipes-or-dplyr-so-can-i-skip-learning-this"><i class="fa fa-check"></i><b>8.7</b> The SOA‚Äôs code doesn‚Äôt use pipes or dplyr, so can I skip learning this?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>9</b> Data manipulation</a><ul>
<li class="chapter" data-level="9.1" data-path="data-manipulation.html"><a href="data-manipulation.html#garbage-in-garbage-out"><i class="fa fa-check"></i><b>9.1</b> Garbage in; garbage out üóë</a></li>
<li class="chapter" data-level="9.2" data-path="data-manipulation.html"><a href="data-manipulation.html#be-a-detective"><i class="fa fa-check"></i><b>9.2</b> Be a detective üîé</a></li>
<li class="chapter" data-level="9.3" data-path="data-manipulation.html"><a href="data-manipulation.html#a-picture-is-worth-a-thousand-words"><i class="fa fa-check"></i><b>9.3</b> A picture is worth a thousand words üì∑</a></li>
<li class="chapter" data-level="9.4" data-path="data-manipulation.html"><a href="data-manipulation.html#factor-or-numeric"><i class="fa fa-check"></i><b>9.4</b> Factor or numeric ‚ùì</a></li>
<li class="chapter" data-level="9.5" data-path="data-manipulation.html"><a href="data-manipulation.html#of-statistics-are-false"><i class="fa fa-check"></i><b>9.5</b> 73.6% of statistics are false üò®</a></li>
<li class="chapter" data-level="9.6" data-path="data-manipulation.html"><a href="data-manipulation.html#how-to-save-time-with-dplyr"><i class="fa fa-check"></i><b>9.6</b> How to save time with dplyr</a></li>
<li class="chapter" data-level="9.7" data-path="data-manipulation.html"><a href="data-manipulation.html#look-at-the-data"><i class="fa fa-check"></i><b>9.7</b> Look at the data</a></li>
<li class="chapter" data-level="9.8" data-path="data-manipulation.html"><a href="data-manipulation.html#transform-the-data"><i class="fa fa-check"></i><b>9.8</b> Transform the data</a></li>
<li class="chapter" data-level="9.9" data-path="data-manipulation.html"><a href="data-manipulation.html#exercises"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li>
<li class="chapter" data-level="9.10" data-path="data-manipulation.html"><a href="data-manipulation.html#answers-to-exercises"><i class="fa fa-check"></i><b>9.10</b> Answers to exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>10</b> Visualization</a><ul>
<li class="chapter" data-level="10.1" data-path="visualization.html"><a href="visualization.html#create-a-plot-object-ggplot"><i class="fa fa-check"></i><b>10.1</b> Create a plot object (ggplot)</a></li>
<li class="chapter" data-level="10.2" data-path="visualization.html"><a href="visualization.html#add-a-plot"><i class="fa fa-check"></i><b>10.2</b> Add a plot</a></li>
<li class="chapter" data-level="10.3" data-path="visualization.html"><a href="visualization.html#data-manipulation-chaining"><i class="fa fa-check"></i><b>10.3</b> Data manipulation chaining</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html"><i class="fa fa-check"></i><b>11</b> Introduction to modeling</a><ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#modeling-vocabulary"><i class="fa fa-check"></i><b>11.1</b> Modeling vocabulary</a></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#modeling-notation"><i class="fa fa-check"></i><b>11.2</b> Modeling notation</a></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#ordinary-least-squares-ols"><i class="fa fa-check"></i><b>11.3</b> Ordinary Least Squares (OLS)</a></li>
<li class="chapter" data-level="11.4" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#regression-vs.-classification"><i class="fa fa-check"></i><b>11.4</b> Regression vs.¬†classification</a></li>
<li class="chapter" data-level="11.5" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#regression-metrics"><i class="fa fa-check"></i><b>11.5</b> Regression metrics</a></li>
<li class="chapter" data-level="11.6" data-path="introduction-to-modeling.html"><a href="introduction-to-modeling.html#example"><i class="fa fa-check"></i><b>11.6</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html"><i class="fa fa-check"></i><b>12</b> Generalized linear Models (GLMs)</a><ul>
<li class="chapter" data-level="12.0.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#assumptions-of-ols"><i class="fa fa-check"></i><b>12.0.1</b> Assumptions of OLS</a></li>
<li class="chapter" data-level="12.0.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#assumptions-of-glms"><i class="fa fa-check"></i><b>12.0.2</b> Assumptions of GLMs</a></li>
<li class="chapter" data-level="12.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>12.1</b> Advantages and disadvantages</a></li>
<li class="chapter" data-level="12.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#glms-for-regression"><i class="fa fa-check"></i><b>12.2</b> GLMs for regression</a></li>
<li class="chapter" data-level="12.3" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>12.3</b> Interpretation of coefficients</a><ul>
<li class="chapter" data-level="12.3.1" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#identity-link"><i class="fa fa-check"></i><b>12.3.1</b> Identity link</a></li>
<li class="chapter" data-level="12.3.2" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#log-link"><i class="fa fa-check"></i><b>12.3.2</b> Log link</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="generalized-linear-models-glms.html"><a href="generalized-linear-models-glms.html#other-links"><i class="fa fa-check"></i><b>12.4</b> Other links</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="glms-for-classification.html"><a href="glms-for-classification.html"><i class="fa fa-check"></i><b>13</b> GLMs for classification</a><ul>
<li class="chapter" data-level="13.1" data-path="glms-for-classification.html"><a href="glms-for-classification.html#binary-target"><i class="fa fa-check"></i><b>13.1</b> Binary target</a></li>
<li class="chapter" data-level="13.2" data-path="glms-for-classification.html"><a href="glms-for-classification.html#count-target"><i class="fa fa-check"></i><b>13.2</b> Count target</a></li>
<li class="chapter" data-level="13.3" data-path="glms-for-classification.html"><a href="glms-for-classification.html#link-functions"><i class="fa fa-check"></i><b>13.3</b> Link functions</a></li>
<li class="chapter" data-level="13.4" data-path="glms-for-classification.html"><a href="glms-for-classification.html#interpretation-of-coefficients-1"><i class="fa fa-check"></i><b>13.4</b> Interpretation of coefficients</a><ul>
<li class="chapter" data-level="13.4.1" data-path="glms-for-classification.html"><a href="glms-for-classification.html#logit"><i class="fa fa-check"></i><b>13.4.1</b> Logit</a></li>
<li class="chapter" data-level="13.4.2" data-path="glms-for-classification.html"><a href="glms-for-classification.html#probit-cauchit-cloglog"><i class="fa fa-check"></i><b>13.4.2</b> Probit, Cauchit, Cloglog</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="glms-for-classification.html"><a href="glms-for-classification.html#example-1"><i class="fa fa-check"></i><b>13.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="classification-metrics.html"><a href="classification-metrics.html"><i class="fa fa-check"></i><b>14</b> Classification metrics</a><ul>
<li class="chapter" data-level="14.1" data-path="classification-metrics.html"><a href="classification-metrics.html#area-under-the-roc-curve-auc"><i class="fa fa-check"></i><b>14.1</b> Area Under the ROC Curve (AUC)</a></li>
<li class="chapter" data-level="14.2" data-path="classification-metrics.html"><a href="classification-metrics.html#additional-reading"><i class="fa fa-check"></i><b>14.2</b> Additional reading</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html"><i class="fa fa-check"></i><b>15</b> Additional GLM topics</a><ul>
<li class="chapter" data-level="15.1" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#residuals"><i class="fa fa-check"></i><b>15.1</b> Residuals</a><ul>
<li class="chapter" data-level="15.1.1" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#raw-residuals"><i class="fa fa-check"></i><b>15.1.1</b> Raw residuals</a></li>
<li class="chapter" data-level="15.1.2" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#deviance-residuals"><i class="fa fa-check"></i><b>15.1.2</b> Deviance residuals</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#example-2"><i class="fa fa-check"></i><b>15.2</b> Example</a></li>
<li class="chapter" data-level="15.3" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#log-transforms-of-continuous-predictors"><i class="fa fa-check"></i><b>15.3</b> Log transforms of continuous predictors</a></li>
<li class="chapter" data-level="15.4" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#reference-levels"><i class="fa fa-check"></i><b>15.4</b> Reference levels</a></li>
<li class="chapter" data-level="15.5" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#interactions"><i class="fa fa-check"></i><b>15.5</b> Interactions</a></li>
<li class="chapter" data-level="15.6" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#offsets"><i class="fa fa-check"></i><b>15.6</b> Offsets</a></li>
<li class="chapter" data-level="15.7" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#tweedie-regression"><i class="fa fa-check"></i><b>15.7</b> Tweedie regression</a></li>
<li class="chapter" data-level="15.8" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#combinations-of-link-functions-and-target-distributions"><i class="fa fa-check"></i><b>15.8</b> Combinations of Link Functions and Target Distributions</a><ul>
<li class="chapter" data-level="15.8.1" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-log-link"><i class="fa fa-check"></i><b>15.8.1</b> Gaussian Response with Log Link</a></li>
<li class="chapter" data-level="15.8.2" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-inverse-link"><i class="fa fa-check"></i><b>15.8.2</b> Gaussian Response with Inverse Link</a></li>
<li class="chapter" data-level="15.8.3" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-identity-link"><i class="fa fa-check"></i><b>15.8.3</b> Gaussian Response with Identity Link</a></li>
<li class="chapter" data-level="15.8.4" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gaussian-response-with-log-link-and-negative-values"><i class="fa fa-check"></i><b>15.8.4</b> Gaussian Response with Log Link and Negative Values</a></li>
<li class="chapter" data-level="15.8.5" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gamma-response-with-log-link"><i class="fa fa-check"></i><b>15.8.5</b> Gamma Response with Log Link</a></li>
<li class="chapter" data-level="15.8.6" data-path="additional-glm-topics.html"><a href="additional-glm-topics.html#gamma-with-inverse-link"><i class="fa fa-check"></i><b>15.8.6</b> Gamma with Inverse Link</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html"><i class="fa fa-check"></i><b>16</b> GLM variable selection</a><ul>
<li class="chapter" data-level="16.1" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#stepwise-subset-selection"><i class="fa fa-check"></i><b>16.1</b> Stepwise subset selection</a></li>
<li class="chapter" data-level="16.2" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#penalized-linear-models"><i class="fa fa-check"></i><b>16.2</b> Penalized Linear Models</a></li>
<li class="chapter" data-level="16.3" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#ridge-regression"><i class="fa fa-check"></i><b>16.3</b> Ridge Regression</a></li>
<li class="chapter" data-level="16.4" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#lasso"><i class="fa fa-check"></i><b>16.4</b> Lasso</a></li>
<li class="chapter" data-level="16.5" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#elastic-net"><i class="fa fa-check"></i><b>16.5</b> Elastic Net</a></li>
<li class="chapter" data-level="16.6" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#advantages-and-disadvantages-1"><i class="fa fa-check"></i><b>16.6</b> Advantages and disadvantages</a></li>
<li class="chapter" data-level="16.7" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#example-ridge-regression"><i class="fa fa-check"></i><b>16.7</b> Example: Ridge Regression</a></li>
<li class="chapter" data-level="16.8" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#example-the-lasso"><i class="fa fa-check"></i><b>16.8</b> Example: The Lasso</a></li>
<li class="chapter" data-level="16.9" data-path="glm-variable-selection.html"><a href="glm-variable-selection.html#references"><i class="fa fa-check"></i><b>16.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>17</b> Tree-based models</a><ul>
<li class="chapter" data-level="17.1" data-path="tree-based-models.html"><a href="tree-based-models.html#decision-trees"><i class="fa fa-check"></i><b>17.1</b> Decision Trees</a><ul>
<li class="chapter" data-level="17.1.1" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-2"><i class="fa fa-check"></i><b>17.1.1</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="tree-based-models.html"><a href="tree-based-models.html#ensemble-learning"><i class="fa fa-check"></i><b>17.2</b> Ensemble learning</a><ul>
<li class="chapter" data-level="17.2.1" data-path="tree-based-models.html"><a href="tree-based-models.html#bagging"><i class="fa fa-check"></i><b>17.2.1</b> Bagging</a></li>
<li class="chapter" data-level="17.2.2" data-path="tree-based-models.html"><a href="tree-based-models.html#boosting"><i class="fa fa-check"></i><b>17.2.2</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="tree-based-models.html"><a href="tree-based-models.html#random-forests"><i class="fa fa-check"></i><b>17.3</b> Random Forests</a><ul>
<li class="chapter" data-level="17.3.1" data-path="tree-based-models.html"><a href="tree-based-models.html#example-3"><i class="fa fa-check"></i><b>17.3.1</b> Example</a></li>
<li class="chapter" data-level="17.3.2" data-path="tree-based-models.html"><a href="tree-based-models.html#variable-importance"><i class="fa fa-check"></i><b>17.3.2</b> Variable Importance</a></li>
<li class="chapter" data-level="17.3.3" data-path="tree-based-models.html"><a href="tree-based-models.html#partial-dependence"><i class="fa fa-check"></i><b>17.3.3</b> Partial dependence</a></li>
<li class="chapter" data-level="17.3.4" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-3"><i class="fa fa-check"></i><b>17.3.4</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="tree-based-models.html"><a href="tree-based-models.html#gradient-boosted-trees"><i class="fa fa-check"></i><b>17.4</b> Gradient Boosted Trees</a><ul>
<li class="chapter" data-level="17.4.1" data-path="tree-based-models.html"><a href="tree-based-models.html#adaboost"><i class="fa fa-check"></i><b>17.4.1</b> AdaBoost</a></li>
<li class="chapter" data-level="17.4.2" data-path="tree-based-models.html"><a href="tree-based-models.html#gradient-boosting"><i class="fa fa-check"></i><b>17.4.2</b> Gradient Boosting</a></li>
<li class="chapter" data-level="17.4.3" data-path="tree-based-models.html"><a href="tree-based-models.html#notation"><i class="fa fa-check"></i><b>17.4.3</b> Notation</a></li>
<li class="chapter" data-level="17.4.4" data-path="tree-based-models.html"><a href="tree-based-models.html#parameters"><i class="fa fa-check"></i><b>17.4.4</b> Parameters</a></li>
<li class="chapter" data-level="17.4.5" data-path="tree-based-models.html"><a href="tree-based-models.html#example-4"><i class="fa fa-check"></i><b>17.4.5</b> Example</a></li>
<li class="chapter" data-level="17.4.6" data-path="tree-based-models.html"><a href="tree-based-models.html#advantages-and-disadvantages-4"><i class="fa fa-check"></i><b>17.4.6</b> Advantages and disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="tree-based-models.html"><a href="tree-based-models.html#exercises-1"><i class="fa fa-check"></i><b>17.5</b> Exercises</a><ul>
<li class="chapter" data-level="17.5.1" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-with-randomforest"><i class="fa fa-check"></i><b>17.5.1</b> 1. RF with <code>randomForest</code></a></li>
<li class="chapter" data-level="17.5.2" data-path="tree-based-models.html"><a href="tree-based-models.html#rf-tuning-with-caret"><i class="fa fa-check"></i><b>17.5.2</b> 2. RF tuning with <code>caret</code></a></li>
<li class="chapter" data-level="17.5.3" data-path="tree-based-models.html"><a href="tree-based-models.html#tuning-a-gbm-with-caret"><i class="fa fa-check"></i><b>17.5.3</b> 3. Tuning a GBM with <code>caret</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>18</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="18.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#principal-component-analysis-pca"><i class="fa fa-check"></i><b>18.1</b> Principal Component Analysis (PCA)</a><ul>
<li class="chapter" data-level="18.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#example-pca-on-us-arrests"><i class="fa fa-check"></i><b>18.1.1</b> Example: PCA on US Arrests</a></li>
<li class="chapter" data-level="18.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#example-pca-on-cancel-cells"><i class="fa fa-check"></i><b>18.1.2</b> Example: PCA on Cancel Cells</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering"><i class="fa fa-check"></i><b>18.2</b> Clustering</a><ul>
<li class="chapter" data-level="18.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-clustering"><i class="fa fa-check"></i><b>18.2.1</b> K-Means Clustering</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#hierarchical-clustering"><i class="fa fa-check"></i><b>18.3</b> Hierarchical Clustering</a><ul>
<li class="chapter" data-level="18.3.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#example-clustering-cancel-cells"><i class="fa fa-check"></i><b>18.3.1</b> Example: Clustering Cancel Cells</a></li>
<li class="chapter" data-level="18.3.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#references-1"><i class="fa fa-check"></i><b>18.3.2</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="references-2.html"><a href="references-2.html"><i class="fa fa-check"></i><b>19</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Analytics for Actuaries</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="glms-for-classification" class="section level1">
<h1><span class="header-section-number"> 13</span> GLMs for classification</h1>
<p>For classification, the predicted values need to be a category instead of a number. Using a discrete target distribution ensures that this will be the case. The probability of an event occurring is <span class="math inline">\(E[Y] = p\)</span>. Unlike the continuous case, all of the link functions have the same range between 0 and 1 because this is a probability.</p>
<div id="binary-target" class="section level2">
<h2><span class="header-section-number">13.1</span> Binary target</h2>
<p>When <span class="math inline">\(Y\)</span> is binary, then the Binomial distribution is the only choice. If there are multiple categories, then the Multinomial should be used.</p>
</div>
<div id="count-target" class="section level2">
<h2><span class="header-section-number">13.2</span> Count target</h2>
<p>When <span class="math inline">\(Y\)</span> is a count, the Poisson distribution is the only choice. Two examples are counting the number of claims which a policy has in a given year or counting the number of people visiting the ER in a given month. The key ingredients are 1) some event, and 2) some fixed period of time.</p>
<p>Statistically, the name for this is a Poisson Process, which is a way of describing a serious of discrete events where the average time between events is known, called the ‚Äúrate‚Äù <span class="math inline">\(\lambda\)</span>, but the exact timing of events is unknown. For a time interval of length <span class="math inline">\(m\)</span>, the expected number of events is <span class="math inline">\(\lambda m\)</span>.</p>
<p>By using a GLM, we can fit a different rate for each observation. In the ER example, each patient would have a different rate. Those who are unhealthy or who work in risky environments would have a higher rate of ER visits than those are healthy and work in offices.</p>
<p><span class="math display">\[Y_i|X_i \sim \text{Poisson}(\lambda_i m_i)\]</span></p>
<p>When all observations have the same exposure, <span class="math inline">\(m = 1\)</span>. When the mean of the data is far from the variance, an additional parameter known as the <em>dispersion parameter</em> is used. A classic example is when modeling insurance claim counts which have a lot of zero claims. Then the model is said to be an ‚Äúover-dispersed Poisson‚Äù or ‚Äúzero-inflated‚Äù model.</p>
</div>
<div id="link-functions" class="section level2">
<h2><span class="header-section-number">13.3</span> Link functions</h2>
<p>There are four link functions. The most common are the Logit and Probit, but the Cauchit and Cloglog did appear on the SOA‚Äôs Hospital Readmissions practice exam in 2019. The identity link does not make sense for classification because it would result in predictions being outside of <span class="math inline">\((0,1)\)</span></p>
<p><img src="images/discrete_link_functions.png" width="1200%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>The <em>logit</em> is also known as the <em>standard logistic function</em> or <em>sigmoid</em> and is also used in deep learning.</p>
</blockquote>
<p>Below we see how the linear predictor (x-axis) gets converted to a probability (y-axis).</p>
<p><img src="Exam-PA-Study-Manual_files/figure-html/unnamed-chunk-109-1.png" width="576" style="display: block; margin: auto;" /></p>
<ul>
<li><span style="color:#85C1E9 ">Logit: </span> Most commonly used; default in R; canonical link for the binomial distribution.</li>
<li><span style="color:purple ">Probit: </span> Sharper curves than the other links which may have best performance for certain data; Inverse CDF of a standard normal distribution makes it easy to explain.</li>
<li><span style="color:red ">Cauchit: </span> Very gradual curves may be best for certain data; CDF for the standard Cauchy distribution which is a t distribution with one degree of freedom.</li>
<li><span style="color:green">Complimentary Log-Log (cloglog)</span> Asymmetric; Important in survival analysis (not on this exam).</li>
</ul>
</div>
<div id="interpretation-of-coefficients-1" class="section level2">
<h2><span class="header-section-number">13.4</span> Interpretation of coefficients</h2>
<p>Interpreting the coefficients in classification is trickier than in classification because the result must always be within <span class="math inline">\((0,1)\)</span>.</p>
<div id="logit" class="section level3">
<h3><span class="header-section-number">13.4.1</span> Logit</h3>
<p>The link function <span class="math inline">\(log(\frac{p}{1-p})\)</span> is known as the log-odds, where the odds are <span class="math inline">\(\frac{p}{1-p}\)</span>. These come up in gambling, where bets are placed on the odds of some event occurring. For example: if the probability of a claim is <span class="math inline">\(p = 0.8\)</span>, then the probability of no claim is 0.2 and the odds of a claim occurring are 0.8/0.2 = 4.</p>
<p>The transformation from probability to odds is monotonic. This is a fancy way of saying that if <span class="math inline">\(p\)</span> increases, then the odds of <span class="math inline">\(p\)</span> increases as well, and vice versa if <span class="math inline">\(p\)</span> decreases. The log transform is monotonic as well.</p>
<p>The net result is that when a variable increases the linear predictor, this increases the log odds, and this increases the log of the odds, and vice versa if the linear predictor decreases. In other words, the signs of the coefficients indicate whether the variable increases or decreases the probability of the event.</p>
</div>
<div id="probit-cauchit-cloglog" class="section level3">
<h3><span class="header-section-number">13.4.2</span> Probit, Cauchit, Cloglog</h3>
<p>These link functions are still monotonic and so the signs of the coefficients can be interpreted to mean that the variable has a positive or negative impact on the target.</p>
<p>More extensive interpretation is not straight-forward. In the case of the Probit, instead of dealing with the log-odds function, we have the inverse CDF of a standard Normal distribution (a.k.a., a Gaussian distribution with mean 0 and variance 1). There is no way of taking this inverse directly.</p>
</div>
</div>
<div id="example-1" class="section level2">
<h2><span class="header-section-number">13.5</span> Example</h2>
<p>Using the <code>auto_claim</code> data, we predict whether or not a policy has a claim. This is also known as the <em>claim frequency</em>.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb217-1" title="1">auto_claim <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(CLM_FLAG)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   CLM_FLAG     n
##   &lt;chr&gt;    &lt;int&gt;
## 1 No        7556
## 2 Yes       2740</code></pre>
<p>About 40% do not have a claim while 60% have at least one claim.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb219-1" title="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb219-2" title="2">index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> auto_claim<span class="op">$</span>CLM_FLAG, </a>
<a class="sourceLine" id="cb219-3" title="3">                             <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> F) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>()</a>
<a class="sourceLine" id="cb219-4" title="4">auto_claim &lt;-<span class="st"> </span>auto_claim <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb219-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">target =</span> <span class="kw">as.factor</span>(<span class="kw">ifelse</span>(CLM_FLAG <span class="op">==</span><span class="st"> &quot;Yes&quot;</span>, <span class="dv">1</span>,<span class="dv">0</span>)))</a>
<a class="sourceLine" id="cb219-6" title="6">train &lt;-<span class="st">  </span>auto_claim <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(index)</a>
<a class="sourceLine" id="cb219-7" title="7">test &lt;-<span class="st"> </span>auto_claim <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>index)</a>
<a class="sourceLine" id="cb219-8" title="8"></a>
<a class="sourceLine" id="cb219-9" title="9">frequency &lt;-<span class="st"> </span><span class="kw">glm</span>(target <span class="op">~</span><span class="st"> </span>AGE <span class="op">+</span><span class="st"> </span>GENDER <span class="op">+</span><span class="st"> </span>MARRIED <span class="op">+</span><span class="st"> </span>CAR_USE <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb219-10" title="10"><span class="st">                   </span>BLUEBOOK <span class="op">+</span><span class="st"> </span>CAR_TYPE <span class="op">+</span><span class="st"> </span>AREA, </a>
<a class="sourceLine" id="cb219-11" title="11">                 <span class="dt">data=</span>train, </a>
<a class="sourceLine" id="cb219-12" title="12">                 <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">&quot;logit&quot;</span>))</a></code></pre></div>
<p>All of the variables except for the <code>CAR_TYPE</code> and <code>GENDERM</code> are highly significant. The car types <code>SPORTS CAR</code> and <code>SUV</code> appear to be significant, and so if we wanted to make the model simpler we could create indicator variables for <code>CAR_TYPE == SPORTS CAR</code> and <code>CAR_TYPE == SUV</code>.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" title="1">frequency <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = target ~ AGE + GENDER + MARRIED + CAR_USE + BLUEBOOK + 
##     CAR_TYPE + AREA, family = binomial(link = &quot;logit&quot;), data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8431  -0.8077  -0.5331   0.9575   3.0441  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)        -3.523e-01  2.517e-01  -1.400  0.16160    
## AGE                -2.289e-02  3.223e-03  -7.102 1.23e-12 ***
## GENDERM            -1.124e-02  9.304e-02  -0.121  0.90383    
## MARRIEDYes         -6.028e-01  5.445e-02 -11.071  &lt; 2e-16 ***
## CAR_USEPrivate     -1.008e+00  6.569e-02 -15.350  &lt; 2e-16 ***
## BLUEBOOK           -4.025e-05  4.699e-06  -8.564  &lt; 2e-16 ***
## CAR_TYPEPickup     -6.687e-02  1.390e-01  -0.481  0.63048    
## CAR_TYPESedan      -3.689e-01  1.383e-01  -2.667  0.00765 ** 
## CAR_TYPESports Car  6.159e-01  1.891e-01   3.256  0.00113 ** 
## CAR_TYPESUV         2.982e-01  1.772e-01   1.683  0.09240 .  
## CAR_TYPEVan        -8.983e-03  1.319e-01  -0.068  0.94569    
## AREAUrban           2.128e+00  1.064e-01  19.993  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 9544.3  on 8236  degrees of freedom
## Residual deviance: 8309.6  on 8225  degrees of freedom
## AIC: 8333.6
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>The signs of the coefficients tell if the probability of having a claim is either increasing or decreasing by each variable. For example, the likelihood of an accident</p>
<ul>
<li>Decreases as the age of the car increases</li>
<li>Is lower for men</li>
<li>Is higher for sports cars and SUVs</li>
</ul>
<p>The p-values tell us if the variable is significant.</p>
<ul>
<li><code>Age</code>, <code>MarriedYes</code>, <code>CAR_USEPrivate</code>, <code>BLUEBOOK</code>, and <code>AreaUrban</code> are significant.</li>
<li>Certain values of <code>CAR_TYPE</code> are significant but others are not.</li>
</ul>
<p>The output is a predicted probability. We can see that this is centered around a probability of about 0.3.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb222-1" title="1">preds &lt;-<span class="st"> </span><span class="kw">predict</span>(frequency, <span class="dt">newdat=</span>test,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb222-2" title="2"><span class="kw">qplot</span>(preds) </a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-113"></span>
<img src="Exam-PA-Study-Manual_files/figure-html/unnamed-chunk-113-1.png" alt="Distribution of Predicted Probability" width="480" />
<p class="caption">
Figure 13.1: Distribution of Predicted Probability
</p>
</div>
<p>In order to convert these values to predicted 0‚Äôs and 1‚Äôs, we assign a <em>cutoff</em> value so that if <span class="math inline">\(\hat{y}\)</span> is above this threshold we use a 1 and 0 otherwise. The default cutoff is 0.5. We change this to 0.3 and see that there are 763 policies predicted to have claims.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb223-1" title="1">test &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">pred_zero_one =</span> <span class="kw">as.factor</span>(<span class="dv">1</span><span class="op">*</span>(preds<span class="op">&gt;</span>.<span class="dv">3</span>)))</a>
<a class="sourceLine" id="cb223-2" title="2"><span class="kw">summary</span>(test<span class="op">$</span>pred_zero_one)</a></code></pre></div>
<pre><code>##    0    1 
## 1296  763</code></pre>
<p>How do we decide on this cutoff value? We need to compare cutoff values based on some evaluation metric. For example, we can use <em>accuracy</em>.</p>
<p><span class="math display">\[\text{Accuracy} = \frac{\text{Correct Guesses}}{\text{Total Guesses}}\]</span></p>
<p>This results in an accuracy of 70%. But is this good?</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.699</code></pre>
<p>Consider what would happen if we just predicted all 0‚Äôs. The accuracy is 74%.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb227-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(<span class="dv">0</span> <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.734</code></pre>
<p>For policies which experience claims the accuracy is 63%.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb229-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb229-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.631</code></pre>
<p>But for policies that don‚Äôt actually experience claims this is 72%.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb231-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb231-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.724</code></pre>
<p>How do we know if this is a good model? We can repeat this process with a different cutoff value and get different accuracy metrics for these groups. Let‚Äôs use a cutoff of 0.6.</p>
<p>75%</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb233-1" title="1">test &lt;-<span class="st"> </span>test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">pred_zero_one =</span> <span class="kw">as.factor</span>(<span class="dv">1</span><span class="op">*</span>(preds<span class="op">&gt;</span>.<span class="dv">6</span>)))</a>
<a class="sourceLine" id="cb233-2" title="2">test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.752</code></pre>
<p>10% for policies with claims and 98% for policies without claims.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb235-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb235-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb235-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.108</code></pre>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb237-1" title="1">test <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb237-2" title="2"><span class="st">  </span><span class="kw">filter</span>(target <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb237-3" title="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accuracy =</span> <span class="kw">mean</span>(pred_zero_one <span class="op">==</span><span class="st"> </span>target))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   accuracy
##      &lt;dbl&gt;
## 1    0.985</code></pre>
<p>The punchline is that the accuracy depends on the cutoff value, and changing the cutoff value changes whether the model is accuracy for the ‚Äútrue = 1‚Äù classes (policies with actual claims) vs.¬†the ‚Äúfalse = 0‚Äù classes (policies without claims).</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models-glms.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification-metrics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sdcastillo/PA-R-Study-Manual/edit/master/05-linear-models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Exam-PA-Study-Manual.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
